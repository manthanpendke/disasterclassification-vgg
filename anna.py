# -*- coding: utf-8 -*-
"""ANNA .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/111Jh_T1yiDQq0Jpnq4HjGz5N2HHwFjnM
"""

# ⚠️ Clears all files/folders inside /content except system defaults (.config, sample_data)
import shutil, os

keep = {'.config', 'sample_data'}
for item in os.listdir('/content'):
    if item not in keep:
        path = os.path.join('/content', item)
        try:
            if os.path.isdir(path):
                shutil.rmtree(path)
            else:
                os.remove(path)
            print("Deleted:", path)
        except Exception as e:
            print("Could not delete:", path, "Error:", e)

print("\n✅ /content cleaned. Only system defaults remain.")
print("Remaining:", os.listdir('/content'))

# =======================================================
# Cell 1: Setup and Data Preparation (Final NumPy Fix)
# =======================================================
print("=== STEP 1: Setting up the environment and downloading data... ===")

# CRITICAL FIX: Keep the default NumPy 2.0 and install compatible versions of other libraries.
# We explicitly install a recent version of opencv-python-headless that supports NumPy 2.0.
!pip install -q "opencv-python-headless>=4.9.0" "ultralytics" "kaggle" "tensorflow"

import os
import subprocess
import shutil
from google.colab import files
import warnings
import tensorflow as tf
import cv2
import numpy as np
from ultralytics import YOLO
import json
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models, optimizers

# Suppress warnings
warnings.filterwarnings('ignore')

# --- Kaggle API Setup ---
if not os.path.exists("/root/.kaggle/kaggle.json"):
    print("\nPlease upload your kaggle.json file.")
    uploaded = files.upload()
    if "kaggle.json" in uploaded:
        os.makedirs("/root/.kaggle", exist_ok=True)
        with open("/root/.kaggle/kaggle.json", "wb") as f:
            f.write(uploaded["kaggle.json"])
        os.chmod("/root/.kaggle/kaggle.json", 0o600)
        print("✅ kaggle.json configured.")
    else:
        raise SystemExit("❌ kaggle.json is required.")

# --- Dataset Download & Setup ---
DATASET_SLUG = "mikolajbabula/disaster-images-dataset-cnn-model"
DEST_DIR = "/content/dataset"
if not os.path.exists(DEST_DIR):
    print(f"\nDownloading dataset '{DATASET_SLUG}'...")
    subprocess.run(["kaggle", "datasets", "download", "-d", DATASET_SLUG, "-p", "/content", "--unzip"], check=True, capture_output=True)
    source_dir = "/content/DisasterModel"
    if os.path.exists(source_dir):
        shutil.move(source_dir, DEST_DIR)
        validation_path = os.path.join(DEST_DIR, "validation")
        valid_path = os.path.join(DEST_DIR, "valid")
        if os.path.exists(validation_path): os.rename(validation_path, valid_path)
    print(f"✅ Dataset is ready at {DEST_DIR}")
else:
    print(f"✅ Dataset already found at {DEST_DIR}")

# --- Define Global Paths & Params ---
TRAIN_DIR = os.path.join(DEST_DIR, 'train')
VALID_DIR = os.path.join(DEST_DIR, 'valid')
TEST_DIR = os.path.join(DEST_DIR, 'test')
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
MODEL_PATH = '/content/disaster_classifier.keras'

# ===================================================================
# Cell 2: Build and Train the VGG16 Classifier (WITH FINE-TUNING)
# ===================================================================
print("\n=== STEP 2: Building and training the VGG16 Classifier with Fine-Tuning... ===")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models, optimizers, Input

# Model parameters
TRAIN_EPOCHS = 10 # Increased epochs for fine-tuning
MODEL_PATH = '/content/disaster_classifier_finetuned.keras' # Use a new model name

# --- Create Data Generators (Unchanged) ---
train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')
val_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')
valid_gen = val_datagen.flow_from_directory(VALID_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')
NUM_CLASSES = len(train_gen.class_indices)
print(f"Found {NUM_CLASSES} classes: {list(train_gen.class_indices.keys())}")

# --- Build and Train the Model (if it doesn't already exist) ---
if not os.path.exists(MODEL_PATH):
    # --- Part 1: Initial Training of Top Layers ---
    print("\n--- Phase 1: Training the top layers ---")

    # Define the input layer
    inputs = Input(shape=(*IMG_SIZE, 3))
    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=inputs)
    base_model.trainable = False # Keep base model frozen for this part

    # Chain the layers together functionally
    x = base_model.output
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)

    classifier_model = models.Model(inputs=inputs, outputs=outputs)
    classifier_model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

    # Train only the top layers for a few epochs to get them stable
    classifier_model.fit(train_gen, validation_data=valid_gen, epochs=4)

    # --- Part 2: Fine-Tuning ---
    print("\n--- Phase 2: Unfreezing layers for Fine-Tuning ---")

    # Unfreeze the last convolutional block of VGG16
    base_model.trainable = True
    for layer in base_model.layers[:-4]: # Keep all but the last 4 layers frozen
        layer.trainable = False

    # Re-compile the model with a VERY low learning rate for fine-tuning
    classifier_model.compile(optimizer=optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

    print(f"Training for {TRAIN_EPOCHS} fine-tuning epochs...")
    history = classifier_model.fit(train_gen, validation_data=valid_gen, epochs=TRAIN_EPOCHS)

    classifier_model.save(MODEL_PATH)
    print(f"✅ Fine-tuned model trained and saved to {MODEL_PATH}")
else:
    print(f"✅ Fine-tuned model {MODEL_PATH} already exists. It will be loaded in subsequent cells.")

# Create a class lookup dictionary
idx_to_label = {v: k for k, v in train_gen.class_indices.items()}

# =====================================================================================
# Cell 3: Define the Full Analysis Pipeline (FINAL ROBUST VERSION)
# =====================================================================================
print("\n=== Defining the full analysis pipeline (Re-Balanced Multi-Factor Model)... ===")

import tensorflow as tf
from tensorflow.keras import Input, Model
from tensorflow.keras.models import load_model
import numpy as np
import cv2
import os
from ultralytics import YOLO
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers

# --- 1. Load BOTH Models & Define Key Variables ---
MODEL_PATH = '/content/disaster_classifier_finetuned.keras'

try:
    # This will work if Cell 2 has been run and variables are in memory
    NUM_CLASSES
    IMG_SIZE
    idx_to_label
except NameError:
    # This is the robust fallback logic if Cell 3 is run alone
    print("Warning: Key variables not found. Inferring from saved model and data directories.")

    # ======================= START OF FIX =======================
    # Infer NUM_CLASSES robustly using the '.units' attribute
    temp_model = load_model(MODEL_PATH)
    NUM_CLASSES = temp_model.layers[-1].units # Use .units instead of .output_shape

    # Infer IMG_SIZE from the model's input layer
    IMG_SIZE = temp_model.input_shape[1:3]

    # Recreate idx_to_label by creating a temporary data generator
    # IMPORTANT: Make sure TRAIN_DIR is defined, or replace '/content/data/train' with your path
    try:
        TRAIN_DIR
    except NameError:
        TRAIN_DIR = '/content/data/train' # Define a default path if it doesn't exist

    temp_datagen = tf.keras.preprocessing.image.ImageDataGenerator()
    temp_gen = temp_datagen.flow_from_directory(
        TRAIN_DIR,
        target_size=IMG_SIZE,
        batch_size=1,
        class_mode='categorical',
        shuffle=False
    )
    idx_to_label = {v: k for k, v in temp_gen.class_indices.items()}
    del temp_model, temp_datagen, temp_gen # Clean up temporary objects
    print(f"Inferred IMG_SIZE={IMG_SIZE}, NUM_CLASSES={NUM_CLASSES}, and class labels.")
    # ======================== END OF FIX ========================


# A) Rebuild the fine-tuned classifier model
inputs = Input(shape=(*IMG_SIZE, 3), name="input_image")
base_model = VGG16(weights='imagenet', include_top=False, input_tensor=inputs)
x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(512, activation='relu')(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)
classifier_model = Model(inputs=inputs, outputs=outputs, name="disaster_classifier")
temp_loaded_model = load_model(MODEL_PATH)
classifier_model.set_weights(temp_loaded_model.get_weights())
del temp_loaded_model
print("✅ Fine-tuned VGG16 Classifier model rebuilt and weights transferred.")

# B) Load YOLO
yolo_model = YOLO('yolov8n.pt')
print("✅ YOLOv8 Object Detection model loaded.")


# --- 2. Define the Three Independent Scoring Functions ---

# FACTOR 1: VGG16 "Attention" Score
last_conv_layer = classifier_model.get_layer("block5_conv3")
grad_model = Model(inputs=classifier_model.inputs, outputs=[last_conv_layer.output, classifier_model.output])

def get_attention_score(img_array, class_idx):
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        class_channel = preds[:, class_idx]
    grads = tape.gradient(class_channel, last_conv_layer_output)
    if grads is None: return 0.0
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    heatmap = tf.squeeze(last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis])
    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10)
    heatmap = heatmap.numpy()
    if np.isnan(heatmap).any(): return 0.0
    intensity = np.mean(heatmap)
    spread = np.sum(heatmap > (np.max(heatmap) * 0.5)) / heatmap.size if np.max(heatmap) > 0 else 0
    return (intensity * 0.5 + spread * 0.5) * 2.0

# FACTOR 2: YOLO "Impact" Score
def get_yolo_impact_score(yolo_results, img_shape):
    critical_object_ids = [0, 2, 7] # person, car, truck
    total_critical_area = 0
    img_area = img_shape[0] * img_shape[1]
    if not yolo_results: return 0.0
    boxes = yolo_results[0].boxes.xyxy.cpu().numpy()
    classes = yolo_results[0].boxes.cls.cpu().numpy()
    for i, box in enumerate(boxes):
        if classes[i] in critical_object_ids:
            x1, y1, x2, y2 = box
            total_critical_area += (x2 - x1) * (y2 - y1)
    density = total_critical_area / img_area
    return min(1.0, density * 10.0)

# FACTOR 3: Image-Wide "Chaos" Score (The Failsafe)
def get_chaos_failsafe_score(original_img):
    gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 100, 200)
    edge_density = np.sum(edges > 0) / edges.size
    return min(1.0, edge_density * 4.0)

# INTELLIGENT CYCLONE BONUS
def get_cyclone_eye_bonus(original_img):
    """Detects a well-defined cyclone eye and returns a score BONUS."""
    gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 5)
    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=100,
                               param1=100, param2=30, minRadius=10, maxRadius=100)
    return 0.3 if circles is not None else 0.0

# --- 3. Define the Main Analysis Function with Weighted Averaging ---
def analyze_disaster_image(image_path):
    original_img = cv2.imread(image_path)
    if original_img is None: return None
    original_img_shape = original_img.shape

    img_vgg = cv2.resize(original_img, IMG_SIZE)
    img_array_vgg = img_to_array(img_vgg)
    img_batch_for_vgg = np.expand_dims(img_array_vgg / 255.0, axis=0)
    predictions = classifier_model.predict(img_batch_for_vgg, verbose=0)
    prediction_values = predictions[0]
    class_idx = np.argmax(prediction_values)
    predicted_class = idx_to_label[class_idx]
    class_confidence = float(prediction_values[class_idx])

    # --- Calculate the three core scores ---
    attention_score = get_attention_score(np.expand_dims(img_array_vgg, axis=0), class_idx)
    yolo_results = yolo_model(original_img, verbose=False)
    impact_score = get_yolo_impact_score(yolo_results, original_img_shape)
    chaos_score = get_chaos_failsafe_score(original_img)

    # --- Combine scores with the standard weighted average ---
    base_severity = (attention_score * 0.5) + (impact_score * 0.3) + (chaos_score * 0.2)

    # --- Add the INTELLIGENT BONUS only if the class is 'cyclone' ---
    if predicted_class == 'cyclone':
        base_severity += get_cyclone_eye_bonus(original_img)

    final_severity = min(1.0, base_severity)

    # --- Assign Authority ---
    authority_map = {
        'cyclone':    lambda s: 'State Emergency Services (SES)' if s < 0.5 else 'National Disaster Response Force (NDRF)',
        'earthquake': lambda s: 'Local Municipality / Search & Rescue' if s < 0.5 else 'NDRF + State Government',
        'flood':      lambda s: 'Municipal Water Dept / SES' if s < 0.5 else 'State Flood Response + NDRF',
        'wildfire':   lambda s: 'Local Fire Brigade' if s < 0.5 else 'National Fire Services + Forest Dept'
    }
    authority_func = authority_map.get(predicted_class, lambda s: "Local Authorities")
    responsible_authority = authority_func(final_severity)

    result = {
        'image_path': os.path.basename(image_path),
        'predicted_class': predicted_class,
        'class_confidence': round(class_confidence, 4),
        'estimated_severity': round(final_severity, 4),
        'responsible_authority': responsible_authority,
    }
    return result

print("✅ Full RE-BALANCED MULTI-FACTOR analysis pipeline is ready.")

# =======================================================
# Cell 4: Run Full Pipeline on the Entire Test Set
# =======================================================
print("\n=== Running the full pipeline on all test images to gather data for evaluation... ===")
import pandas as pd
import glob
from tqdm.notebook import tqdm

image_paths = glob.glob(f"{TEST_DIR}/**/*.jpg", recursive=True)
results_list = []
for path in tqdm(image_paths, desc="Analyzing Test Images"):
    true_class = os.path.basename(os.path.dirname(path))
    analysis = analyze_disaster_image(path)
    analysis['true_class'] = true_class
    results_list.append(analysis)

df_results = pd.DataFrame(results_list)
print(f"\n✅ Analysis complete for {len(df_results)} test images.")

# ==============================================================
# Cell 6: Performance Metrics for the Classification Model
# ==============================================================
print("\n=== Part 1: Quantitative Metrics for the Classifier (VGG16) ===")

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix

y_true = df_results['true_class']
y_pred = df_results['predicted_class']
class_labels = sorted(df_results['true_class'].unique())

print("\n------------------- Classification Report -------------------")
print(classification_report(y_true, y_pred, target_names=class_labels))
print("-----------------------------------------------------------\n")

print("------------------- Confusion Matrix -------------------")
cm = confusion_matrix(y_true, y_pred, labels=class_labels)
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(10, 8))
sns.heatmap(cm_normalized, annot=True, fmt=".2f", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.title("Normalized Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()
print("------------------------------------------------------\n")

# ====================================================================
# Cell 7: Qualitative Analysis for the Severity Estimator (YOLOv8)
# ====================================================================
print("\n=== Part 2: Qualitative Analysis for the Severity Estimator ===")

import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.preprocessing.image import load_img

print("\n----------- Distribution of Severity Scores by Class -----------")
plt.figure(figsize=(12, 7))
sns.boxplot(x='true_class', y='estimated_severity', data=df_results)
plt.title("Distribution of Estimated Severity Scores for Each True Disaster Class")
plt.xlabel("True Disaster Class")
plt.ylabel("Estimated Severity Score")
plt.show()

print("\n----------- Highest vs. Lowest Severity Images -----------")
class_labels = sorted(df_results['true_class'].unique())
fig, axes = plt.subplots(len(class_labels), 2, figsize=(10, 15))
fig.suptitle("Comparison of Lowest and Highest Severity Images per Class", fontsize=16)

for i, label in enumerate(class_labels):
    class_df = df_results[df_results['true_class'] == label]
    lowest_severity_row = class_df.loc[class_df['estimated_severity'].idxmin()]
    highest_severity_row = class_df.loc[class_df['estimated_severity'].idxmax()]

    lowest_img_path = os.path.join(TEST_DIR, label, lowest_severity_row['image_path'])
    highest_img_path = os.path.join(TEST_DIR, label, highest_severity_row['image_path'])

    ax = axes[i, 0]
    ax.imshow(load_img(lowest_img_path))
    ax.set_title(f"Class: {label}\nLowest Severity: {lowest_severity_row['estimated_severity']:.4f}")
    ax.axis('off')

    ax = axes[i, 1]
    ax.imshow(load_img(highest_img_path))
    ax.set_title(f"Class: {label}\nHighest Severity: {highest_severity_row['estimated_severity']:.4f}")
    ax.axis('off')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()
print("----------------------------------------------------------")

# =======================================================
# Final Cell: Upload an image and get the analysis
# =======================================================
from google.colab import files
import matplotlib.pyplot as plt
import cv2
import json
import os

print("Please upload an image to analyze...")
uploaded = files.upload()

if uploaded:
    # Get the path of the uploaded file
    uploaded_image_path = list(uploaded.keys())[0]

    # Run the full analysis using the function defined in the previous cell
    result = analyze_disaster_image(uploaded_image_path)

    print("\n--- ANALYSIS RESULT ---")
    print(json.dumps(result, indent=2))
    print("-----------------------")

    # Display the image with YOLO bounding boxes for visual verification
    img_for_display = cv2.imread(uploaded_image_path)
    yolo_results = yolo_model(img_for_display, verbose=False)
    img_with_boxes = yolo_results[0].plot() # .plot() draws the boxes on the image

    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.title(f"Analysis for: '{result['image_path']}'")
    plt.show()
else:
    print("\nNo image was uploaded.")